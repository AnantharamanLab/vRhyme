#! /usr/bin/env python3
# vRhyme
# Author: Kristopher Kieft
# University of Wisconsin-Madison

import subprocess
import pickle
import sys
from sklearn.cluster import MiniBatchKMeans
from itertools import combinations


def edge_check(x,y,max_edges):
    '''
    Check if one of the nodes passed max edges threshold
    '''
    check = False
    if x <= max_edges or y <= max_edges:
        check = True

    return check

def cc_calc(Nv,Kv,k):
    '''
    Calculate clustering coefficient.
    0.36 is an optimized constant
    '''
    cc = (2*Nv)/(Kv*(Kv-1))
    if cc <= 0.36 and cc > 0:
        k += 1
    return k

def cluster_coeff(names,data):
    '''
    Generate information for clustering coefficient calculation
    '''
    data = set(data)
    k = 1
    for x in names:
        neighbors = set([d[1] for d in data if d[0] == x] + [d[0] for d in data if d[1] == x])
        Kv = len(neighbors)
        
        if Kv > 1:
            pairs = [tuple(map(int, comb)) for comb in combinations(neighbors, 2)]
            overlaps = [p for p in pairs if p in data] + [p for p in pairs if (p[1],p[0]) in data]
            Nv = len(overlaps)
            k = cc_calc(Nv,Kv,k)

    return k


def network_stuff(net_data, folder, bin_size, refine_m, max_edges, iteration):
    '''
    Main wrapper for generating clusters/networks of bins.
    Clusters are generated by connected nodes.
    Automatic refinement with KMeans clustering.
    '''
    if len(net_data) == 0:
        return
    
    net_data.sort(key = lambda x: x[2])

    counter = {}
    data = []
    edge_list = []
    bins = {}
    edges = {}
    duos = {}
    b = 1

    for item in net_data:
        qry = item[0]
        sbj = item[1]

        try:
            q = counter[qry]
            q += 1
            counter[qry] = q
        except Exception:
            counter[qry] = 1
            q = 1
        try:
            s = counter[sbj]
            s += 1
            counter[sbj] = s
        except Exception:
            counter[sbj] = 1
            s = 1

        check = edge_check(q,s,max_edges)
        if check == True:
            edge = item[2]
            added = False
            for key in bins:
                value = bins[key]
                if qry in value or sbj in value:
                    value.update([qry,sbj])
                    bins[key] = value
                    edges[key].append(edge)
                    duos[key].append((qry,sbj))
                    added = True
                    break

            if added == False:
                bins[b] = set([qry,sbj])
                edges[b] = [edge]
                duos[b] = [(qry,sbj)]
                b += 1

    counter = None
    net_data = None

    while True:
        names = list(bins.keys())
        l = len(names)
        alter = False
        for i in range(0,l-1):
            for j in range(i+1,l):
                x = names[i]
                y = names[j]

                try:
                    x_values = bins[x]
                    y_values = bins[y]

                    if x_values & y_values != set():
                        x_values = x_values.union(y_values)
                        bins[x] = x_values
                        duos[x].extend(duos[y])
                        edges[x].extend(edges[y])

                        del bins[y]
                        del duos[y]
                        del edges[y]
                        alter = True

                except Exception:
                    # y was deleted
                    pass

        if alter == False: # nothing was combined
            break

    names = None
    delete_bins = []
    sort_duos = {}

    for key,names in bins.items():
        mems = len(names)
        if mems >= bin_size:
            zip_duo_w = list(zip(duos[key],edges[key]))
            zip_duo_w.sort(key=lambda x: x[1])
            sort_duos[key] = zip_duo_w
        else:
            delete_bins.append(key)

    delete_bins = set(delete_bins)
    for k in delete_bins:
        del bins[k]

    delete_bins = None
    edges = None
    duos = None

    final_bins = {}
    b = 1
    for key,data in sort_duos.items():
        data = [i[0] for i in data]
        names = bins[key]
        ln = len(names)
        k = cluster_coeff(names,data) 

        removed = set()
        if k >= 3 and ln >= refine_m:
            batch = int(ln * 0.25)
            if batch < 2:
                batch = 2
            elif batch > 100:
                batch = 100
            clstr = MiniBatchKMeans(n_clusters=k, random_state=4, batch_size=batch, max_iter=100, verbose=0, max_no_improvement=5, n_init=5)

            labels = clstr.fit_predict(data)
            zz = list(zip(data,labels))
            l = set(labels)
            temp_bins = {i:[] for i in l}

            for z in zz:
                l = z[1]
                val = z[0]
                d1 = val[0]
                d2 = val[1]
                if d1 not in removed:
                    temp_bins[l].append(d1)
                    removed.add(d1)
                if d2 not in removed:
                    temp_bins[l].append(d2)
                    removed.add(d2)

            for t in temp_bins.values():
                if len(t) >= bin_size:
                    final_bins[b] = set(t)
                    b += 1
        else:
            final_bins[b] = names
            b += 1

    with open(folder + iteration + ".vRhyme-bins.tsv", "w") as net_out:
        s = 0
        for val in final_bins.values():
            names = list(val)
            s += len(names)

            names = [str(n) for n in names]
            names = '\t'.join(names)
            net_out.write(f'{names}\n')

    b = len(final_bins)
    bins = None


if __name__ == '__main__':
    folder = sys.argv[2]
    bin_size = int(sys.argv[3])
    refine_m = int(sys.argv[4])
    max_edges = int(sys.argv[5])
    iteration = sys.argv[6]

    with open(sys.argv[1], 'rb') as read_net:
        net_data = pickle.load(read_net)

    network_stuff(net_data, folder, bin_size, refine_m, max_edges, iteration)

    subprocess.run('rm ' + sys.argv[1], shell=True)


#
#
#
